import os
import json
import openai
import hashlib
from datetime import datetime
from pathlib import Path

# LlamaIndex ç›¸å…³æ¨¡å—
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import Settings, StorageContext, load_index_from_storage, VectorStoreIndex
from llama_index.core.readers import SimpleDirectoryReader
from llama_index.core.tools import FunctionTool
from llama_index.core.agent import ReActAgent
from llama_index.core.node_parser import SimpleNodeParser

# ===================== è®¾ç½® OpenAI æ¥å£ =====================
openai.api_key = "sk-42kUEMoma40GUNhl595bE5D53e994eC59a7a469534564f11"
openai.base_url = "https://api.gptapi.us/v1"

# é…ç½® LlamaIndex å…¨å±€è®¾ç½®
Settings.llm = OpenAI(model="gpt-4o",
                      api_key=openai.api_key,
                      base_url=openai.base_url)
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")


# ===================== å·¥å…·å‡½æ•°ï¼šè®¡ç®—æ–‡ä»¶å“ˆå¸Œ =====================
def compute_file_hash(file_path: Path) -> str:
    with open(file_path, "rb") as f:
        content = f.read()
    return hashlib.sha256(content).hexdigest()


# ===================== æ„å»ºæˆ–å¢é‡æ›´æ–°ç´¢å¼• =====================
def update_vuln_kb_index(index_dir: str, data_dir: str) -> VectorStoreIndex:
    current_files = {
        os.path.abspath(os.path.join(data_dir, f))
        for f in os.listdir(data_dir)
        if os.path.isfile(os.path.join(data_dir, f))
    }

    try:
        storage_context = StorageContext.from_defaults(persist_dir=index_dir)
        index = load_index_from_storage(storage_context)
        print("âœ… æˆåŠŸåŠ è½½å·²æœ‰ç´¢å¼•ã€‚")

        existing_file_paths = set()
        for node in storage_context.docstore.docs.values():
            file_path = node.metadata.get("file_path")
            if file_path:
                existing_file_paths.add(os.path.abspath(file_path))

        new_files = current_files - existing_file_paths
        deleted_files = existing_file_paths - current_files

        if new_files:
            new_documents = SimpleDirectoryReader(
                input_files=list(new_files)).load_data()
            new_nodes = SimpleNodeParser().get_nodes_from_documents(
                new_documents)
            index.insert_nodes(new_nodes)
            print(f"âœ… å·²æ›´æ–°æ–‡æ¡£æ•°ï¼š{len(new_files)}")
        else:
            print("â„¹ï¸ æ²¡æœ‰æ–°æ–‡æ¡£éœ€è¦æ›´æ–°ã€‚")

        if deleted_files:
            delete_ids = []
            for node_id, node in storage_context.docstore.docs.items():
                file_path = node.metadata.get("file_path")
                if file_path and os.path.abspath(file_path) in deleted_files:
                    delete_ids.append(node_id)
            if delete_ids:
                index.delete_nodes(delete_ids)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤å¤±æ•ˆèŠ‚ç‚¹æ•°ï¼š{len(delete_ids)}")
        else:
            print("âœ… æ‰€æœ‰èŠ‚ç‚¹æ–‡ä»¶ä»ç„¶å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤ã€‚")

    except Exception as e:
        print(f"âš ï¸ ç´¢å¼•åŠ è½½å¤±è´¥ï¼Œæ­£åœ¨é‡å»ºï¼š{e}")
        documents = SimpleDirectoryReader(input_dir=data_dir).load_data()
        index = VectorStoreIndex.from_documents(documents)
        index.storage_context.persist(persist_dir=index_dir)
        print("âœ… ç´¢å¼•é‡å»ºå®Œæˆã€‚")

    index.storage_context.persist(persist_dir=index_dir)
    return index


# ===================== åˆ›å»º Agent å’Œå·¥å…· =====================
vuln_kb_index = update_vuln_kb_index(index_dir="./storage/vuln_kb",
                                     data_dir="./data/vuln_kb")
kb_engine = vuln_kb_index.as_query_engine(similarity_top_k=3)


def query_kb(query: str) -> str:
    response = kb_engine.query(query)
    answer = response.response.strip()

    references = []
    for i, node_with_score in enumerate(response.source_nodes):
        node = node_with_score.node
        file_path = node.metadata.get("file_path", "æœªçŸ¥æ–‡ä»¶")
        content = node.get_content().strip()
        references.append(f"ã€å¼•ç”¨{i+1}ã€‘æ–‡ä»¶ï¼š`{file_path}`\næ‘˜å½•å†…å®¹ï¼š\n> {content}")

    full_response = f"{answer}\n\nå¼•ç”¨å†…å®¹ï¼š\n" + "\n\n".join(references)
    return full_response


kb_tool = FunctionTool.from_defaults(
    fn=query_kb,
    name="vuln_knowledge_base",
    description="æä¾›æ¼æ´èƒŒæ™¯çŸ¥è¯†ï¼Œå¦‚åŸç†ã€å±å®³å’Œä¿®å¤å»ºè®®ã€‚è¾“å…¥æ˜¯æ¼æ´åç§°ï¼Œå¦‚ SQL æ³¨å…¥")

report_agent = ReActAgent.from_tools(tools=[kb_tool],
                                     llm=Settings.llm,
                                     verbose=True)

# ===================== ä¸»ç¨‹åºå…¥å£ =====================
if __name__ == "__main__":
    try:
        with open("result.json", "r", encoding="utf-8") as f:
            decision_data = json.load(f)
    except Exception as e:
        print(f"è¯»å–å†³ç­– Agent è¾“å‡ºæ–‡ä»¶å¤±è´¥ï¼š{e}")
        exit(1)

    input_desc = "ä¸‹é¢æ˜¯æ¼æ´æ£€æµ‹å™¨è¾“å‡ºçš„ç»“æœ JSONï¼š\n"
    input_desc += json.dumps(decision_data, ensure_ascii=False, indent=2)
    input_desc += "\n\nè¯·åˆ†æè¿™ä¸ª JSONï¼Œå¹¶æŒ‰å¦‚ä¸‹æ ¼å¼ç”ŸæˆmarkdownæŠ¥å‘Šï¼š\n"
    input_desc += "\nè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ¯ä¸ªæ¼æ´é¡¹çš„æŠ¥å‘Šå†…å®¹ï¼ˆMarkdown æ ¼å¼ï¼‰ï¼š\n"
    input_desc += """
### æ¼æ´å‡½æ•°åï¼š`<function_name>`
- **æ¼æ´ä½ç½®**ï¼š<location>
- **é£é™©ç­‰çº§**ï¼š<severity>
- **æ¼æ´ç±»å‹**ï¼š<vulnerability_type>
- **æ¼æ´æè¿°**ï¼š
  <ä¸­æ–‡çš„description>
- **ä¿®å¤å»ºè®®**ï¼š
  <å»ºè®®çš„ä¿®å¤æ–¹æ³•>
---
"""
    input_desc += "\nè¯·åŠ¡å¿…åœ¨æ¯æ¡æ¼æ´æŠ¥å‘Šä¸­å†™å‡ºä½ å¼•ç”¨çš„æ–‡ä»¶è·¯å¾„åŠå†…å®¹ç‰‡æ®µï¼Œç”¨å¦‚ä¸‹æ ¼å¼ï¼š\n"
    input_desc += "æ¥è‡ªæ–‡ä»¶ï¼š`<file_path>`\nå†…å®¹èŠ‚é€‰ï¼š\n> è¢«å¼•ç”¨çš„å†…å®¹\n"

    result = report_agent.chat(input_desc)
    print("\nç”Ÿæˆçš„æŠ¥å‘Šå†…å®¹å¦‚ä¸‹ï¼š\n")
    print(result.response)

    try:
        with open("vulnerability_report.md", "w", encoding="utf-8") as f:
            f.write(result.response)
        print("âœ… æŠ¥å‘Šå·²ä¿å­˜ä¸º vulnerability_report.md")
    except Exception as e:
        print(f"âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥ï¼š{e}")
